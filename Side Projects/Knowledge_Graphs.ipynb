{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import bs4\n",
    "import requests\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "from spacy.matcher import Matcher \n",
    "from spacy.tokens import Span \n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import matplotlib.pyplot as pltnnn\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4318, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_sentences = pd.read_csv(\"NLP/wiki_sentences_v2.csv\")\n",
    "candidate_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(sent):\n",
    "  ## chunk 1\n",
    "  ent1 = \"\"\n",
    "  ent2 = \"\"\n",
    "\n",
    "  prv_tok_dep = \"\"    # dependency tag of previous token in the sentence\n",
    "  prv_tok_text = \"\"   # previous token in the sentence\n",
    "\n",
    "  prefix = \"\"\n",
    "  modifier = \"\"\n",
    "\n",
    "  #############################################################\n",
    "  \n",
    "  for tok in nlp(sent):\n",
    "    ## chunk 2\n",
    "    # if token is a punctuation mark then move on to the next token\n",
    "    if tok.dep_ != \"punct\" and tok.dep_ != \"det\":\n",
    "      # check: token is a compound word or not\n",
    "      if tok.dep_ == \"compound\":\n",
    "        prefix = tok.text\n",
    "        # if the previous word was also a 'compound' then add the current word to it\n",
    "        if prv_tok_dep == \"compound\":\n",
    "          prefix = prv_tok_text + \" \"+ tok.text\n",
    "      \n",
    "      # check: token is a modifier or not\n",
    "      if tok.dep_.endswith(\"mod\") == True:\n",
    "        modifier = tok.text\n",
    "        # if the previous word was also a 'compound' then add the current word to it\n",
    "        if prv_tok_dep == \"compound\":\n",
    "          modifier = prv_tok_text + \" \"+ tok.text\n",
    "      \n",
    "      ## chunk 3\n",
    "      if tok.dep_.find(\"subj\") == True:\n",
    "        ent1 = modifier +\" \"+ prefix + \" \"+ tok.text\n",
    "        prefix = \"\"\n",
    "        modifier = \"\"\n",
    "        prv_tok_dep = \"\"\n",
    "        prv_tok_text = \"\"      \n",
    "\n",
    "      ## chunk 4\n",
    "      if tok.dep_.find(\"obj\") == True:\n",
    "        ent2 = modifier +\" \"+ prefix +\" \"+ tok.text\n",
    "        \n",
    "      ## chunk 5  \n",
    "      # update variables\n",
    "      prv_tok_dep = tok.dep_\n",
    "      prv_tok_text = tok.text\n",
    "  #############################################################\n",
    "\n",
    "  return [ent1.strip(), ent2.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4318/4318 [00:28<00:00, 150.58it/s]\n"
     ]
    }
   ],
   "source": [
    "entity_pairs = []\n",
    "\n",
    "for i in tqdm(candidate_sentences[\"sentence\"]):\n",
    "    entity_pairs.append(get_entities(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['we', 'tests'],\n",
       " ['m global', 'international sales rights'],\n",
       " ['canadian musician robbie robertson', 'soundtrack'],\n",
       " ['it', 'original music tracks'],\n",
       " ['it', 'reviewed  franchise'],\n",
       " ['she', 'accidentally  mystique'],\n",
       " ['military  forces', 'arrest'],\n",
       " ['train', 'vuk'],\n",
       " ['', 'telepath selene gallio'],\n",
       " ['singer', 'sequel']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_pairs[10:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relation(sent):\n",
    "\n",
    "  doc = nlp(sent)\n",
    "\n",
    "  # Matcher class object \n",
    "  matcher = Matcher(nlp.vocab)\n",
    "\n",
    "  #define the pattern \n",
    "  pattern = [{'DEP':'ROOT'}, \n",
    "            {'DEP':'prep','OP':\"?\"},\n",
    "            {'DEP':'agent','OP':\"?\"},  \n",
    "            {'POS':'ADJ','OP':\"?\"}] \n",
    "\n",
    "  matcher.add(\"matching_1\", None, pattern) \n",
    "\n",
    "  matches = matcher(doc)\n",
    "  k = len(matches) - 1\n",
    "\n",
    "  span = doc[matches[k][1]:matches[k][2]] \n",
    "\n",
    "  return(span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4318/4318 [00:27<00:00, 156.77it/s]\n"
     ]
    }
   ],
   "source": [
    "relations = [get_relation(i) for i in tqdm(candidate_sentences['sentence'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract subject\n",
    "source = [i[0] for i in entity_pairs]\n",
    "\n",
    "# extract object\n",
    "target = [i[1] for i in entity_pairs]\n",
    "\n",
    "kg_df = pd.DataFrame({'source':source, 'target':target, 'edge':relations})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create a directed-graph from a dataframe\n",
    "G=nx.from_pandas_edgelist(kg_df, \"source\", \"target\", \n",
    "                          edge_attr=True, create_using=nx.MultiDiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pykeen==1.0.5\n",
      "  Downloading pykeen-1.0.5-py3-none-any.whl (319 kB)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from pykeen==1.0.5) (1.0.5)\n",
      "Processing c:\\users\\marco\\appdata\\local\\pip\\cache\\wheels\\76\\03\\bb\\589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\\sklearn-0.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy in c:\\users\\marco\\anaconda3\\lib\\site-packages (from pykeen==1.0.5) (1.18.5)\n",
      "Requirement already satisfied: click in c:\\users\\marco\\anaconda3\\lib\\site-packages (from pykeen==1.0.5) (7.1.2)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Collecting optuna>=2.0.0\n",
      "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
      "Collecting click-default-group\n",
      "  Downloading click-default-group-1.2.2.tar.gz (3.3 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\marco\\anaconda3\\lib\\site-packages (from pykeen==1.0.5) (4.47.0)\n",
      "Collecting dataclasses-json\n",
      "  Downloading dataclasses_json-0.5.6-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\marco\\anaconda3\\lib\\site-packages (from pykeen==1.0.5) (2.24.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->pykeen==1.0.5) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->pykeen==1.0.5) (2.8.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\marco\\anaconda3\\lib\\site-packages (from sklearn->pykeen==1.0.5) (0.23.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from optuna>=2.0.0->pykeen==1.0.5) (1.3.18)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\marco\\anaconda3\\lib\\site-packages (from optuna>=2.0.0->pykeen==1.0.5) (5.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from optuna>=2.0.0->pykeen==1.0.5) (20.4)\n",
      "Collecting cmaes>=0.8.2\n",
      "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
      "Collecting cliff\n",
      "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
      "Requirement already satisfied: scipy!=1.4.0 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from optuna>=2.0.0->pykeen==1.0.5) (1.5.0)\n",
      "Collecting alembic\n",
      "  Downloading alembic-1.7.6-py3-none-any.whl (210 kB)\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting marshmallow-enum<2.0.0,>=1.5.1\n",
      "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.3.0\n",
      "  Downloading marshmallow-3.14.1-py3-none-any.whl (47 kB)\n",
      "Collecting typing-inspect>=0.4.0\n",
      "  Downloading typing_inspect-0.7.1-py3-none-any.whl (8.4 kB)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from requests->pykeen==1.0.5) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from requests->pykeen==1.0.5) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from requests->pykeen==1.0.5) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from requests->pykeen==1.0.5) (2.10)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas>=1.0.0->pykeen==1.0.5) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn->pykeen==1.0.5) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn->pykeen==1.0.5) (0.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from packaging>=20.0->optuna>=2.0.0->pykeen==1.0.5) (2.4.7)\n",
      "Collecting cmd2>=1.0.0\n",
      "  Downloading cmd2-2.4.0-py3-none-any.whl (150 kB)\n",
      "Collecting stevedore>=2.0.1\n",
      "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
      "Collecting autopage>=0.4.0\n",
      "  Downloading autopage-0.5.0-py3-none-any.whl (29 kB)\n",
      "Collecting pbr!=2.1.0,>=2.0.0\n",
      "  Downloading pbr-5.8.1-py2.py3-none-any.whl (113 kB)\n",
      "Collecting PrettyTable>=0.7.2\n",
      "  Downloading prettytable-3.1.1-py3-none-any.whl (26 kB)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.1.6-py2.py3-none-any.whl (75 kB)\n",
      "Collecting importlib-resources; python_version < \"3.9\"\n",
      "  Downloading importlib_resources-5.4.0-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.9\" in c:\\users\\marco\\anaconda3\\lib\\site-packages (from alembic->optuna>=2.0.0->pykeen==1.0.5) (1.7.0)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\users\\marco\\anaconda3\\lib\\site-packages (from colorlog->optuna>=2.0.0->pykeen==1.0.5) (0.4.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from typing-inspect>=0.4.0->dataclasses-json->pykeen==1.0.5) (4.0.1)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
      "Collecting pyreadline3; sys_platform == \"win32\"\n",
      "  Downloading pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "Requirement already satisfied: attrs>=16.3.0 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna>=2.0.0->pykeen==1.0.5) (19.3.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna>=2.0.0->pykeen==1.0.5) (0.2.5)\n",
      "Collecting pyperclip>=1.6\n",
      "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from Mako->alembic->optuna>=2.0.0->pykeen==1.0.5) (1.1.1)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in c:\\users\\marco\\anaconda3\\lib\\site-packages (from importlib-resources; python_version < \"3.9\"->alembic->optuna>=2.0.0->pykeen==1.0.5) (3.1.0)\n",
      "Building wheels for collected packages: click-default-group, pyperclip\n",
      "  Building wheel for click-default-group (setup.py): started\n",
      "  Building wheel for click-default-group (setup.py): finished with status 'done'\n",
      "  Created wheel for click-default-group: filename=click_default_group-1.2.2-py3-none-any.whl size=3389 sha256=e5e10a441496c8cfc568dd8c28b55b7fec5d5d78af2ea4e6e30c1ca856feb213\n",
      "  Stored in directory: c:\\users\\marco\\appdata\\local\\pip\\cache\\wheels\\7e\\9f\\ec\\d087477ddc7c2807136ca08eb01b5f00e66da90eb4dbf323ab\n",
      "  Building wheel for pyperclip (setup.py): started\n",
      "  Building wheel for pyperclip (setup.py): finished with status 'done'\n",
      "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11113 sha256=bf2c43b58195ccf538595857c96384ef4fe4421469e71d18f2073f6e69170bad\n",
      "  Stored in directory: c:\\users\\marco\\appdata\\local\\pip\\cache\\wheels\\7f\\1a\\65\\84ff8c386bec21fca6d220ea1f5498a0367883a78dd5ba6122\n",
      "Successfully built click-default-group pyperclip\n",
      "Installing collected packages: sklearn, tabulate, cmaes, pyreadline3, pyperclip, cmd2, pbr, stevedore, autopage, PrettyTable, cliff, Mako, importlib-resources, alembic, colorlog, optuna, click-default-group, marshmallow, marshmallow-enum, mypy-extensions, typing-inspect, dataclasses-json, pykeen\n",
      "Successfully installed Mako-1.1.6 PrettyTable-3.1.1 alembic-1.7.6 autopage-0.5.0 click-default-group-1.2.2 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.0 colorlog-6.6.0 dataclasses-json-0.5.6 importlib-resources-5.4.0 marshmallow-3.14.1 marshmallow-enum-1.5.1 mypy-extensions-0.4.3 optuna-2.10.0 pbr-5.8.1 pykeen-1.0.5 pyperclip-1.8.2 pyreadline3-3.4.1 sklearn-0.0 stevedore-3.5.0 tabulate-0.8.9 typing-inspect-0.7.1\n"
     ]
    }
   ],
   "source": [
    "! pip install pykeen==1.0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
